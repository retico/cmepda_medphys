{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture8_demo_CAE_semantic_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/retico/cmepda_medphys/blob/master/L8_code/Lecture8_demo_CAE_semantic_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEXs3Fzs_RMs"
      },
      "source": [
        "## Convolutional autoencoder (CAE) for semantic segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04HYmYOSQbS3"
      },
      "source": [
        "Semantic Segmentation is a classic Computer Vision problem which involves taking as input some raw data (e.g. 2D or 3D images) and converting them into a mask with regions of interest highlighted.\n",
        "\n",
        "**Objective**\n",
        "\n",
        "We will train a Convolutional Auto-Encoder (CAE) to segment mass lesions in mammograms. \n",
        "\n",
        "We will use the dataset made available at: \n",
        "\n",
        "https://drive.google.com/drive/folders/1-HoF6Qy8lrw4-LANXDL1lOTJTH9XXsDy?usp=sharing\n",
        "\n",
        "You can either add this folder to your drive (\"Add shortcut to drive\") or download the large_sample_Im_segmented_ref.zip we wil use, which contains 177 mass examples (104 benign and 73 malignant masses) and the segmentation masks.\n",
        "\n",
        "**Legend of file names** \n",
        "\n",
        "Mass lesions represented in each image.pgm are malignant if the file name ends with “_1.pgm”, benign if it ends with “_2.pgm”, e.g.: \n",
        "\n",
        "0007p1_1_1.pgm contains a malignant mass\n",
        "\n",
        "0003f1_1_1_2.pgm contains a benign mass\n",
        "\n",
        "\n",
        "**Segmented masses.**\n",
        "\n",
        "The folders whose name ends with \"_ref\", e.g. \n",
        "\n",
        "small_sample_Im_segmented_ref/ and \n",
        "\n",
        "large_sample_Im_segmented_ref/\n",
        "\n",
        "contain for each original IMAGE or the small or large sample the IMAGE_resized.pgm and the IMAGE_mass_mask.pgm (which has the same size of the IMAGE_resized.pgm).\n",
        "These lesion segmentation masks have been generated with segmentation code mass_segment.m developed in Lecture5 (cfr. https://github.com/retico/cmepda_medphys)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9pGqDKO_do7"
      },
      "source": [
        "## Reading data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85dNXPXH5EKb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHMZbpSo5S-2"
      },
      "source": [
        "!unzip -q /content/gdrive/My\\ Drive/cmepda_medphys_dataset/IMAGES/Mammography_masses/large_sample_Im_segmented_ref.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTXcVb4d_vT7"
      },
      "source": [
        "##  Dataset overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMKlrTJq6iCB"
      },
      "source": [
        "import os\n",
        "import PIL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aKlUu546OO-"
      },
      "source": [
        "dataset_path = \"/content/large_sample_Im_segmented_ref\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JikOsFAwACxu"
      },
      "source": [
        "We have two kinds of images: *_resized*, i.e. the images containing the mass lesions, and *_mass_mask*, i.e. the lesion masks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb7zFuZu6MOO"
      },
      "source": [
        "!ls /content/large_sample_Im_segmented_ref/ | head -n 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNUFr8Rc6jj8"
      },
      "source": [
        "PIL.Image.open(os.path.join(dataset_path, \"0069p1_4_2_resized.pgm\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muKhL0cC6ooN"
      },
      "source": [
        "PIL.Image.open(os.path.join(dataset_path, \"0069p1_4_2_mass_mask.pgm\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-gK-WIeAbOC"
      },
      "source": [
        "## Reading the images in memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By-YBLYq7I_9"
      },
      "source": [
        "import glob\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpPSQbTP7R3a"
      },
      "source": [
        "def read_dataset(dataset_path, x_id =\"_resized\", y_id=\"_mass_mask\"):\n",
        "    fnames = glob.glob(os.path.join(dataset_path, f\"*{x_id}.pgm\"  ))\n",
        "    X = []\n",
        "    Y = []\n",
        "    for fname in fnames:\n",
        "        X.append(imread(fname)[1:,1:,np.newaxis])\n",
        "        Y.append(imread(fname.replace(x_id, y_id))[1:,1:,np.newaxis])\n",
        "    return np.array(X), np.array(Y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGkZ2WaH7VuH"
      },
      "source": [
        "X,Y = read_dataset(dataset_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21vmpLNyy1yC"
      },
      "source": [
        "print(X.shape, Y.shape)\n",
        "print(X.min(), X.max(), Y.min(), Y.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC3k5ZWb17By"
      },
      "source": [
        "X = X/255\n",
        "Y = Y/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCiheBdKV469"
      },
      "source": [
        "# Train and test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GI4VzmsOjVS"
      },
      "source": [
        "We split the dataset in a train and a test sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z53TqLr8Rfxw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_ZhTzzFQ1OP"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_LMQDVIRwg9"
      },
      "source": [
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlCOsvKN1gZM"
      },
      "source": [
        "We will use the *train set* (X_train) to train the model (allowing for an internal train-validation split). We will leave apart the *test set* (X_test) to evaluate the model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0AStooEBK0N"
      },
      "source": [
        "# Defining and training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_V-rwX6BPXm"
      },
      "source": [
        "We are trying to define a convolutional autoencoder. Inthe paper by (Liu et al, \n",
        "*Deep convolutional neural network and 3D deformable approach for tissue segmentation in musculoskeletal Magnetic Resonance Imaging*, Magn Reson Med 2018; 79(4):2379-2391, https://onlinelibrary.wiley.com/doi/10.1002/mrm.26841 there is an example of a possible architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xursHLl17qiB"
      },
      "source": [
        "from keras.layers import Conv2D, Conv2DTranspose, Input\n",
        "from keras.models import Model, load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUg99av17uf1"
      },
      "source": [
        "def make_model(shape=(124,124,1)):\n",
        "    input_tensor = Input(shape=shape)\n",
        "    x = Conv2D(32, (5, 5), strides=2, padding='same', activation='relu')(input_tensor)\n",
        "    x = Conv2D(64, (3,3), strides=2,  padding='same', activation='relu')(x)\n",
        "    x = Conv2D(128, (3,3), strides=2, padding='same', activation='relu')(x)\n",
        "\n",
        "    x = Conv2DTranspose(64, (3,3), strides=2,  padding='same', activation='relu')(x)\n",
        "    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)\n",
        "    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)\n",
        "    out = Conv2D(1, (5,5), padding='valid',activation='sigmoid')(x) #era tanh\n",
        "    model = Model(input_tensor, out)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VbopgOW8jHN"
      },
      "source": [
        "model = make_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnFKmobu8ls8"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['MAE']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usYLqkuW9EWk"
      },
      "source": [
        "history = model.fit(X_train,Y_train, validation_split=0.2, epochs=250)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMEXhaAT3bEW"
      },
      "source": [
        "We can visualize the loss and the MAE on train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8kARurO3W99"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.semilogy(history.history['loss'])\n",
        "plt.semilogy(history.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.figure()\n",
        "plt.semilogy(history.history['MAE'])\n",
        "plt.semilogy(history.history['val_MAE'])\n",
        "plt.legend(['MAE', 'val_MAE'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72L1r0_l6CzT"
      },
      "source": [
        "We can choose to save the model weights (save_best_only=True) that realized the best performance on the internal validation set (*early stop*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H88d0nxM6bXH"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"model.{epoch:02d}-{val_MAE:.4f}.h5\", \n",
        "    monitor='val_MAE', \n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='auto', save_freq='epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s473cqnwQodZ"
      },
      "source": [
        "We build a 'new' model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNyje0RLQcsU"
      },
      "source": [
        "model = make_model()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['MAE']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJE-yzP6QF0p"
      },
      "source": [
        "We need to make an additional train-validation split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ-ArPuX6-fn"
      },
      "source": [
        "history = model.fit(X_train,Y_train, validation_split=0.2, epochs=200, callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqdssfPm7h5S"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.figure()\n",
        "plt.plot(history.history['MAE'])\n",
        "plt.plot(history.history['val_MAE'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrDQo-7d7n4f"
      },
      "source": [
        "!ls -ltr /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbjMWEWy5Qkx"
      },
      "source": [
        "We can load a saved model, and evaluate its performance on the test examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUwlHW3i-3wQ"
      },
      "source": [
        "#!cp /content/gdrive/My\\ Drive/cmepda_medphys_dataset/NETS/autoenc_mammo_mass.h5 /content/\n",
        "model = load_model(\"/content/model.195-0.0286.h5\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITX7enr-Agsr"
      },
      "source": [
        "We visualize the output on images of the train set ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z98CFc6ArCl"
      },
      "source": [
        "idx=67\n",
        "xtrain = X_train[idx][np.newaxis,...]\n",
        "ytrain = Y_train[idx][np.newaxis,...]\n",
        "xtrain.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olnBs2QBBAcB"
      },
      "source": [
        "plt.figure(figsize=(14,4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(xtrain.squeeze())\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(ytrain.squeeze())\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(model.predict(xtrain).squeeze()>0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXHwsl4VArdu"
      },
      "source": [
        "and on images of the test set (never seen by the CAE) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQWKrcag8XAl"
      },
      "source": [
        "idx=18\n",
        "xtest = X_test[idx][np.newaxis,...]\n",
        "ytest = Y_test[idx][np.newaxis,...]\n",
        "xtest.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv5tz1Or9S-1"
      },
      "source": [
        "plt.figure(figsize=(14,4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(xtest.squeeze())\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(ytest.squeeze())\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(model.predict(xtest).squeeze()>0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbC-AWdRBSwr"
      },
      "source": [
        "# Evaluation of the performance\n",
        "\n",
        "We can quantify the segmentation performance on the train and test in terms of the Dice index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVZ98-ek_NL7"
      },
      "source": [
        "def dice(pred, true, k = 1):\n",
        "    intersection = np.sum(pred[true==k]) * 2.0\n",
        "    dice = intersection / (np.sum(pred) + np.sum(true))\n",
        "    return dice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgt22cBnNkCF"
      },
      "source": [
        "We compute the Dice index for the train examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr7Zx6xuNjtv"
      },
      "source": [
        "idx=67\n",
        "\n",
        "xtrain = X_train[idx][np.newaxis,...]\n",
        "ytrain = Y_train[idx][np.newaxis,...]\n",
        "print(Y_train[idx].shape, ytrain.shape)\n",
        "\n",
        "ypred = model.predict(xtrain).squeeze()>0.2\n",
        "ytrue = Y_train[idx].squeeze()\n",
        "print(ypred.shape, ytrue.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FGpqypDPL9C"
      },
      "source": [
        "dice_value = dice(ypred, ytrue)\n",
        "print(dice_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHSjx_HnY6DJ"
      },
      "source": [
        "We want to compute the Dice index for all images in the np.arrays of the train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JmkVmsVAbcQ"
      },
      "source": [
        "def dice_vectorized(pred, true, k = 1):\n",
        "    intersection = 2.0 *np.sum(pred * (true==k), axis=(1,2,3))\n",
        "    dice = intersection / (pred.sum(axis=(1,2,3)) + true.sum(axis=(1,2,3))) \n",
        "    return dice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7YM2lQ4A9v2"
      },
      "source": [
        "dice_vectorized(ytrain,model.predict(xtrain)>0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH7semtvSSRl"
      },
      "source": [
        "The average Dice on the train set is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A3Q0KvWFWf4"
      },
      "source": [
        "dice_vectorized(Y_train,model.predict(X_train)>0.2).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZpQkTaGGGgu"
      },
      "source": [
        "dice_vectorized(Y_test,model.predict(X_test)>0.2).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6iYdIIyZQuB"
      },
      "source": [
        "You can explore the dependence of the average Dice values on the threshold used to binarize the CAE output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxXsPSMjP3hT"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM2BIc_uacWZ"
      },
      "source": [
        "If we have a limited number of training examples, as usually happens in medical image analysis, we can artificially augment the dataset by applying transformation to the images and lesions masks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZBXov63a13s"
      },
      "source": [
        "We can use the Keras ImageDataGenerator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezy52lW0P0Wt"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LChDnmIsQUcB"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='reflect')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pm5ViJpQUcE"
      },
      "source": [
        "transform = train_datagen.get_random_transform((124,124))\n",
        "transform\n",
        "#x = train_datagen.apply_transform(im, transform)\n",
        "#y = train_datagen.apply_transform(label, transform)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wsclph3CMhT"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "class MassesSequence(Sequence):\n",
        "    \"\"\" Data augmentation class for a CAE \"\"\"\n",
        "\n",
        "    def __init__(self, x, y, img_gen, batch_size=10, shape=(124,124)):\n",
        "        \"\"\" Initialize the sequence\n",
        "\n",
        "        Parameters:\n",
        "\n",
        "        x (np.array): images\n",
        "        y (np.array): labels\n",
        "        batch_size (int): batch size\n",
        "        img_gen (ImageDatagenerator): a Keras ImageDataGenerator instance\n",
        "        shape (tuple): image shape. Default (124, 124)\n",
        "\n",
        "        \"\"\"\n",
        "        self.x, self.y = x, y\n",
        "        self.shape = shape\n",
        "        self.img_gen = img_gen\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Shuffle the dataset at the end of each epoch.\"\"\"\n",
        "        self.x, self.y = shuffle(self.x, self.y)\n",
        "\n",
        "    def process(self, img, transform):\n",
        "        \"\"\" Apply a transformation to an image \"\"\"\n",
        "        img = self.img_gen.apply_transform(img, transform)\n",
        "        return img\n",
        "            \n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "            \n",
        "        X=[];\n",
        "        Y=[];\n",
        "        for image, label in zip(self.x, self.y):\n",
        "            transform = self.img_gen.get_random_transform(self.shape)\n",
        "            X.append(self.process(image, transform))\n",
        "            Y.append(self.process(label, transform)>0.2)\n",
        "\n",
        "          \n",
        "        return np.array(X), np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if5m8Thjb0nW"
      },
      "source": [
        "We have at this time to manually split the Train dataset in a Train_tr and a Train_val dataset in order to use an internal validation set during the model.fit. \n",
        "\n",
        "We then augment only the Train_tr set and use the Train_val dataset as it is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Uls_hxcMB4"
      },
      "source": [
        "X_train_tr, X_train_val, Y_train_tr, Y_train_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOcyFpT-DbDW"
      },
      "source": [
        "mass_gen = MassesSequence(X_train_tr, Y_train_tr, train_datagen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGVYMnT9dEYe"
      },
      "source": [
        "We can have a look at the mass_gen output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA7BeoWqDc7L"
      },
      "source": [
        "batch = mass_gen[6]\n",
        "print(batch[0].shape, batch[1].shape) # they are the data (X) and the masks (Y), respectively"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hxUSznbDjDR"
      },
      "source": [
        "plt.imshow(np.squeeze(batch[0][1]))\n",
        "plt.figure()\n",
        "plt.imshow(np.squeeze(batch[1][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OibbELCJesCX"
      },
      "source": [
        "We train the model with augmented data and save the model at the best epoch on the internal validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i149URENoCnq"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"model_augm.{epoch:02d}-{val_MAE:.4f}.h5\", \n",
        "    monitor='val_MAE', \n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='auto', save_freq='epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ1S5oGdDl4E"
      },
      "source": [
        "model = make_model()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['MAE']) \n",
        "history_augm = model.fit(mass_gen, steps_per_epoch=len(mass_gen), epochs=100, validation_data=(X_train_val, Y_train_val), callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxTIXvLJfixu"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history_augm.history['loss'])\n",
        "plt.plot(history_augm.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.figure()\n",
        "plt.plot(history_augm.history['MAE'])\n",
        "plt.plot(history_augm.history['val_MAE'])\n",
        "plt.legend(['MAE', 'val_MAE'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5418TAWSyzH"
      },
      "source": [
        "# Evaluation of the performance of the augmented model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG_Kui2xf2Vd"
      },
      "source": [
        "!ls -ltr /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn9itrr1Jzlw"
      },
      "source": [
        "You can load one of the models saved in /content/ folder, e.g the last saved best model on the internal validation set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_jcLVScWB5q"
      },
      "source": [
        "model = load_model(\"/content/model_augm.82-0.0255.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfn0VxZQku3E"
      },
      "source": [
        "I saved a model trained for 250 epochs on this train set (i.e. obtained with a train_test_split fixed random state of '42' in the first Train-Test split and of '24' in the Train_tr-Train_val split).\n",
        "\n",
        "The saved model with weigths can be found on\n",
        "https://drive.google.com/drive/folders/1dkv_3J6SbzXu5J1yV-W6uidGDZr1zJxn\n",
        "\n",
        "As before, you can add a shorthcut to this folder to your drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAQIafrclDWF"
      },
      "source": [
        "!cp /content/gdrive/My\\ Drive/cmepda_medphys_dataset/NETS/autoenc_mammo_mass_augm_model_augm.137-0.0183.h5 /content/model_augm.137-0.0183.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL4CqbQmsWZs"
      },
      "source": [
        "model = load_model(\"/content/model_augm.137-0.0183.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCdxL0Y5S-et"
      },
      "source": [
        "Average Dice index on the Train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7d43tvaS9mp"
      },
      "source": [
        "dice_vectorized(Y_train,model.predict(X_train)>0.2).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btmyfz59TBwT"
      },
      "source": [
        "Average Dice index on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv-ENaGi4vTA"
      },
      "source": [
        "dice_vectorized(Y_test,model.predict(X_test)>0.2).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbBMR6uvkP9V"
      },
      "source": [
        "We can have a look at some test images and their segmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUvo-ugSkO6H"
      },
      "source": [
        "idx=30\n",
        "xtest = X_test[idx][np.newaxis,...]\n",
        "ytest = Y_test[idx][np.newaxis,...]\n",
        "plt.figure(figsize=(14,4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(xtest.squeeze())\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(ytest.squeeze())\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(model.predict(xtest).squeeze()>0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys0BvwIdKNiw"
      },
      "source": [
        "# To do\n",
        "*   You can repeat the CAE training by changing the random state in the train_test_split to check the stability of the results against the train-val-test dataset composition.\n",
        "*   You can explore the impact of using diffeent optimizers (with different parameters) and metrics in the training phase (e.g. MAPE instead of MAE).\n",
        "* You can change the model parameters. \n",
        "* ...\n",
        "\n"
      ]
    }
  ]
}